{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdD_8Vyswkwf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_S1JfaW8bIN"
      },
      "outputs": [],
      "source": [
        "# Fix randomness and hide warnings\n",
        "SEED = 76998669\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings as wr\n",
        "wr.simplefilter(action='ignore', category=FutureWarning)\n",
        "wr.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(SEED)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TRtQ5GupYFB"
      },
      "outputs": [],
      "source": [
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(SEED)\n",
        "tf.compat.v1.set_random_seed(SEED)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-bFXdFXttTn"
      },
      "outputs": [],
      "source": [
        "# Import other libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53DAEfQuI41_"
      },
      "source": [
        "### Load and process the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeRE_ISSnySA"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/GioBar00/AN2DL_23-24_Apple_Elixir_dataset/blob/46007b747f81ae768377893548949e31135fbc34/public_data_clean.npz\n",
        "\n",
        "# Load dataset\n",
        "dataset = np.load('public_data_clean.npz', allow_pickle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KEYS = list(dataset.keys())\n",
        "IMAGES = dataset[KEYS[0]]\n",
        "LABELS = dataset[KEYS[1]]\n",
        "\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(SEED)\n",
        "tf.compat.v1.set_random_seed(SEED)\n",
        "\n",
        "# VARIABLES\n",
        "indices_meme = []\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# CONFIGURATION\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "wr.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "wr.simplefilter(action=\"ignore\", category=Warning)\n",
        "\n",
        "#np.random.seed(SEED)\n",
        "#rnd.seed(SEED)\n",
        "\n",
        "\n",
        "# FUNCTIONS\n",
        "def plot_losses(history, figsize):\n",
        "  plt.figure(figsize=figsize)\n",
        "  plt.plot(history['loss'], label='Training Loss', alpha=.8)\n",
        "  plt.plot(history['val_loss'], label='Validation Loss', alpha=.8)\n",
        "  plt.title('Loss')\n",
        "  plt.legend()\n",
        "  plt.grid(alpha=.3)\n",
        "\n",
        "  plt.figure(figsize=figsize)\n",
        "  plt.plot(history['accuracy'], label='Training Accuracy', alpha=.8)\n",
        "  plt.plot(history['val_accuracy'], label='Validation Accuracy', alpha=.8)\n",
        "  plt.title('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.grid(alpha=.3)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def apple_elixir_model(input_shape, output_shape, seed=SEED):\n",
        "\n",
        "  tf.random.set_seed(seed)\n",
        "  # Build the neural network layer by layer\n",
        "  input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "  x = tfkl.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',name='conv00')(input_layer)\n",
        "  x = tfkl.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',name='conv01')(x)\n",
        "  x = tfkl.MaxPooling2D(name='mp0')(x)\n",
        "\n",
        "  x = tfkl.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu',name='conv10')(x)\n",
        "  x = tfkl.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu',name='conv11')(x)\n",
        "  x = tfkl.MaxPooling2D(name='mp1')(x)\n",
        "\n",
        "  x = tfkl.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu',name='conv20')(x)\n",
        "  x = tfkl.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu',name='conv21')(x)\n",
        "  x = tfkl.MaxPooling2D(name='mp2')(x)\n",
        "\n",
        "  x = tfkl.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu',name='conv30')(x)\n",
        "  x = tfkl.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu',name='conv31')(x)\n",
        "  x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "\n",
        "  \n",
        "  x = tfkl.Dense(units = 30, activation='relu')(x)\n",
        "  x = tfkl.Dense(units = 20, activation='relu')(x)\n",
        "\n",
        "  output_layer = tfkl.Dense(units=output_shape ,activation='softmax',name='Output')(x)\n",
        "\n",
        "  # Connect input and output through the Model class\n",
        "  model = tfk.Model(inputs=input_layer, outputs=output_layer, name='Convnet')\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(weight_decay=5e-4), metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Binary Classification Problem -> Sigmoid instead of Softmax for the Output, but you need to change the way you assign the value\n",
        "\n",
        "\n",
        "# images = np.array(images).reshape(5004, 96*96*3)\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "labels_num = list(map(lambda x: [0,1] if x == \"healty\" else [1,0], labels))\n",
        "labels_num = np.array(labels_num)\n",
        "\n",
        "X_train_val, X_test, Y_train_val, Y_test = train_test_split(images, labels_num, test_size=500, random_state=SEED, stratify=labels_num)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=500, random_state=SEED, stratify=Y_train_val)\n",
        "\n",
        "print('Training Set Shape: ', X_train.shape, Y_train.shape)\n",
        "print('Validation Set Shape: ', X_val.shape, Y_val.shape)\n",
        "print('Test Set Shape: ', X_test.shape, Y_test.shape)\n",
        "print()\n",
        "\n",
        "# Normalise\n",
        "X_train = X_train/255\n",
        "X_val = X_val/255\n",
        "X_test = X_test/255\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "output_shape = Y_train[1:]\n",
        "print(f'Input shape of the Network {input_shape}')\n",
        "print()\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 500\n",
        "\n",
        "model = apple_elixir_model(input_shape=input_shape,output_shape = output_shape)\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "  x = X_train, # We need to apply the preprocessing thought for the MobileNetV2 network\n",
        "  y = Y_train,\n",
        "  batch_size = 16,\n",
        "  epochs = 200,\n",
        "  validation_data = (X_val, Y_val), # We need to apply the preprocessing thought for the MobileNetV2 network\n",
        "  callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n",
        ").history\n",
        "\n",
        "\n",
        "\n",
        "plot_losses(history=history, figsize=(20,2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
