{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "# %cd /gdrive/MyDrive/AN2DL/Homework2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Data Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://storage.googleapis.com/storage.barbiero.dev/AN2DL/Homework_2/training_data_clean.npy\n",
    "!wget -q https://storage.googleapis.com/storage.barbiero.dev/AN2DL/Homework_2/categories_clean.npy\n",
    "!wget -q https://storage.googleapis.com/storage.barbiero.dev/AN2DL/Homework_2/series_length_clean.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update Tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deafault Imports\n",
    "import os\n",
    "import logging\n",
    "import warnings as wr\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from keras import layers as tkl\n",
    "from keras import models as tkm\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# from dateutil.parser import parse\n",
    "# from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomness & Warinings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Configuration - All\n",
    "RND = False\n",
    "if not RND:\n",
    "  SEED = 42\n",
    "  os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "  tf.compat.v1.set_random_seed(SEED)\n",
    "  tf.random.set_seed(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  rnd.seed(SEED)\n",
    "\n",
    "# OS Configuration\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
    "\n",
    "# Warning Congiguration\n",
    "wr.simplefilter(action='ignore', category=FutureWarning)\n",
    "wr.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# TensorFlow Configuration\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Plotting Configuration\n",
    "plt.rc('font', size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TPU Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_tpu = True\n",
    "\n",
    "if 'COLAB_TPU_ADDR' in os.environ and use_tpu:\n",
    "  TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
    "else:\n",
    "  use_tpu = False\n",
    "\n",
    "if use_tpu:\n",
    "  tpu_address = TF_MASTER\n",
    "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TF_MASTER)\n",
    "  tf.config.experimental_connect_to_cluster(resolver)\n",
    "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "  strategy = tf.distribute.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initiate Data Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading Datasets RAW\n",
    "# TD = np.load(\"/gdrive/MyDrive/AN2DL/Homework2/training_data.npy\", allow_pickle=True)\n",
    "# VP = np.load(\"/gdrive/MyDrive/AN2DL/Homework2/valid_periods.npy\", allow_pickle=True)\n",
    "# CG = np.load(\"/gdrive/MyDrive/AN2DL/Homework2/categories.npy\", allow_pickle=True)\n",
    "\n",
    "# Loading Datasets CLEAN\n",
    "TD = np.load(\"training_data_clean.npy\", allow_pickle=True)\n",
    "VP = np.load(\"series_length_clean.npy\", allow_pickle=True)\n",
    "CG = np.load(\"categories_clean.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe Unified CLEAN\n",
    "DATA = []\n",
    "\n",
    "for i, l in enumerate(VP):\n",
    "  ts_clipped = TD[i, :l]\n",
    "  DATA.append(ts_clipped)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'TimeSeries': [ts.tolist() for ts in DATA],\n",
    "    'Category': CG.flatten(),\n",
    "    'Length': VP.flatten()\n",
    "})\n",
    "df['Category'] = df['Category'].map({0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F'})\n",
    "\n",
    "dft = df['TimeSeries']\n",
    "dfc = df['Category']\n",
    "\n",
    "print(df['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stats of the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.DataFrame()\n",
    "dd = pd.DataFrame()\n",
    "# Avarage Length\n",
    "avg_length_cat = df.groupby('Category')['Length'].mean().round(2)\n",
    "df_cat['AVG Length'] = avg_length_cat\n",
    "\n",
    "# Less than 50 Elements\n",
    "threshold = 50\n",
    "df_cat['Below 50 (pcs)'] = df.groupby('Category')['Length'].apply(lambda x: (x < threshold).sum())\n",
    "df_cat['Below 50 (%)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).mean()*100).round(2)\n",
    "\n",
    "# Less than 75 Elements\n",
    "threshold = 75\n",
    "df_cat['Below 75 (pcs)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).sum())\n",
    "df_cat['Below 75 (%)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).mean()*100).round(2)\n",
    "\n",
    "# Less than 100 Elements\n",
    "threshold = 100\n",
    "df_cat['Below 100 (pcs)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).sum())\n",
    "df_cat['Below 100 (%)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).mean()*100).round(2)\n",
    "\n",
    "# Less than 150 Elements\n",
    "threshold = 150\n",
    "df_cat['Below 150 (pcs)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).sum())\n",
    "df_cat['Below 150 (%)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).mean()*100).round(2)\n",
    "\n",
    "# Less than 200 Elements\n",
    "threshold = 200\n",
    "df_cat['Below 200 (pcs)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).sum())\n",
    "df_cat['Below 200 (%)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).mean()*100).round(2)\n",
    "\n",
    "# Less than 218 Elements\n",
    "threshold = 218\n",
    "df_cat['Below 218 (pcs)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).sum())\n",
    "df_cat['Below 218 (%)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).mean()*100).round(2)\n",
    "\n",
    "# Less than 536 Elements\n",
    "threshold = 536\n",
    "df_cat['Below 536 (pcs)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).sum())\n",
    "df_cat['Below 536 (%)'] = df.groupby('Category')['Length'].apply(lambda x: (x<threshold).mean()*100).round(2)\n",
    "\n",
    "print(df_cat[['AVG Length']])\n",
    "print()\n",
    "print(df_cat[['Below 50 (pcs)', 'Below 50 (%)']])\n",
    "print(df_cat[['Below 75 (pcs)', 'Below 75 (%)']])\n",
    "print(df_cat[['Below 100 (pcs)', 'Below 100 (%)']])\n",
    "print(df_cat[['Below 150 (pcs)', 'Below 150 (%)']])\n",
    "print(df_cat[['Below 200 (pcs)', 'Below 200 (%)']])\n",
    "print(df_cat[['Below 218 (pcs)', 'Below 218 (%)']])\n",
    "print(df_cat[['Below 536 (pcs)', 'Below 536 (%)']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Category Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "df_A = df[df['Category'] == 'A']\n",
    "df_B = df[df['Category'] == 'B']\n",
    "df_C = df[df['Category'] == 'C']\n",
    "df_D = df[df['Category'] == 'D']\n",
    "df_E = df[df['Category'] == 'E']\n",
    "df_F = df[df['Category'] == 'F']\n",
    "\n",
    "df_AB = pd.concat([df_A, df_B], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Plot Functions\n",
    "def print_timeseries(n, random, norm):\n",
    "  for i in range(n):\n",
    "    if random:\n",
    "      j = np.random.randint(0,len(df))\n",
    "    else:\n",
    "      j=i\n",
    "    print(dfc[j], \"Length: \",len(dft[j]))\n",
    "    if norm:\n",
    "      plt.plot(range(len(dft[j])), [x*100 for x in dft[j]], label=f'Time Series {i + 1}')\n",
    "    else:\n",
    "      plt.plot(range(len(dft[j])), dft[j], label=f'Time Series {i + 1}')\n",
    "\n",
    "    plt.title(f'#{j}')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('Value')\n",
    "    # plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return j\n",
    "def print_category(n, rows, cols, category):\n",
    "  indices = []\n",
    "\n",
    "  if n > rows*cols:\n",
    "    print(\"Please add more rooms\")\n",
    "    return\n",
    "\n",
    "  fig, axes = plt.subplots(rows, cols, figsize=(15*cols,5*rows))\n",
    "  for i in range(n):\n",
    "    j = np.random.randint(0, len(df))\n",
    "\n",
    "    while dfc[j] != category or j in indices:\n",
    "      j = np.random.randint(0, len(df))\n",
    "\n",
    "    row_i = i // cols\n",
    "    col_i = i % cols\n",
    "\n",
    "    print(dfc[j], \"Length: \",len(dft[j]))\n",
    "    axes[row_i, col_i].plot(range(len(dft[j])), dft[j], label=f'Time Series {i + 1}')\n",
    "    axes[row_i, col_i].set_title(f'#{j}')\n",
    "    axes[row_i, col_i].set_xlabel('Time Index')\n",
    "    axes[row_i, col_i].set_ylabel('Value')\n",
    "\n",
    "    indices.append(j)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Augmentation\" CLEAN\n",
    "def build_sequence(df, window=200, stride=200, telescope=18):\n",
    "  actual_window = window + telescope\n",
    "  new_categories = []\n",
    "  X = []                                                                        # 2d (number of series, window size)\n",
    "  y = []                                                                        # 2d (number of series, telescope)\n",
    "\n",
    "  for i in range(len(df)):\n",
    "    ts = df['TimeSeries'][i]\n",
    "    length = df['Length'][i]\n",
    "    category = df['Category'][i]\n",
    "\n",
    "    new_stride = stride\n",
    "    n_windows = int(np.ceil((length - actual_window) / new_stride)) + 1         # number of windows\n",
    "    if n_windows < 1:\n",
    "      n_windows = 1\n",
    "    if n_windows > 1:                                                           # evalute the stride again\n",
    "      new_stride = int((length - actual_window) / (n_windows - 1))\n",
    "\n",
    "    start_idx = length - actual_window                                          # start from the end of the series\n",
    "    end_idx = length\n",
    "    for j in range(n_windows):\n",
    "      if start_idx < 0:\n",
    "        start_idx = 0\n",
    "        end_idx = actual_window\n",
    "        if end_idx > length:\n",
    "          end_idx = length\n",
    "\n",
    "      X.append(ts[start_idx:end_idx - telescope])\n",
    "      y.append(ts[end_idx - telescope:end_idx])\n",
    "      new_categories.append(category)\n",
    "\n",
    "      start_idx -= new_stride\n",
    "      end_idx -= new_stride\n",
    "\n",
    "  return np.array(X), np.array(y), new_categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CONV_LSTM_model(input_shape, output_shape):\n",
    "    assert input_shape[0] >= output_shape[0], \"For this exercise we want input time steps to be >= of output time steps\"\n",
    "\n",
    "    # Define the input layer with the specified shape\n",
    "    input_layer = tkl.Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    # Add a Bidirectional LSTM layer with 64 units\n",
    "    x = tkl.Bidirectional(tkl.LSTM(input_shape[0], return_sequences=True, name='lstm_1'), name='bidirectional_lstm_1')(input_layer)\n",
    "    x = tkl.MultiHeadAttention(num_heads=1, key_dim=input_shape[0], dropout=0.2)(x, x)\n",
    "    x = tkl.Bidirectional(tkl.LSTM(input_shape[0], return_sequences=True, name='lstm_2'), name='bidirectional_lstm_2')(x)\n",
    "    x = tkl.Dense(units=output_shape[1], activation = 'linear')(x)\n",
    "    x = tkl.Flatten()(x)\n",
    "    x = tkl.Dense(units=output_shape[0])(x)\n",
    "\n",
    "    output_layer = tkl.Reshape((-1, 1))(x)\n",
    "\n",
    "    # Construct the model by connecting input and output layers\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n",
    "\n",
    "    # Compile the model with Mean Squared Error loss and Adam optimizer\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTR, XTE = train_test_split(df_A, test_size=0.20, stratify=df_A['Category'], random_state=SEED)\n",
    "XTR = XTR.reset_index(drop=True)\n",
    "XTE = XTE.reset_index(drop=True)\n",
    "\n",
    "print(XTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN = 50\n",
    "TEL = 18\n",
    "STR = 25\n",
    "ATL = 3\n",
    "\n",
    "XTR_ = XTR[XTR['Length'] >= WIN+TEL]\n",
    "XTE_ = XTR[XTR['Length'] >= WIN+TEL]\n",
    "XTR_ = XTR_.reset_index(drop=True)\n",
    "XTE_ = XTE_.reset_index(drop=True)\n",
    "\n",
    "X_train, y_train, cat_train = build_sequence(df=XTR_, window=WIN, stride=STR, telescope=TEL)\n",
    "X_test, y_test, cat_test = build_sequence(df=XTE_, window=WIN, stride=STR, telescope=TEL)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "y_train = np.expand_dims(y_train, axis=-1)\n",
    "y_test = np.expand_dims(y_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the batch size\n",
    "if use_tpu:\n",
    "  BATCH_SIZE = 128\n",
    "else:\n",
    "  BATCH_SIZE = 128\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_trainset(dataset):\n",
    "    return (\n",
    "        dataset\n",
    "        .cache()\n",
    "        .shuffle(1000, reshuffle_each_iteration=True)\n",
    "        .repeat()\n",
    "        .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    )\n",
    "\n",
    "def prepare_valset(dataset):\n",
    "    return (\n",
    "        dataset\n",
    "        .cache()\n",
    "        .repeat()\n",
    "        .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    )\n",
    "\n",
    "train_dataset = prepare_trainset(train_dataset)\n",
    "val_dataset = prepare_valset(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "output_shape = y_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_tpu:\n",
    "  with strategy.scope():\n",
    "    model = build_CONV_LSTM_model(input_shape, output_shape)\n",
    "else:\n",
    "  model = build_CONV_LSTM_model(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "    epochs=300,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(X_test) // BATCH_SIZE,\n",
    "    callbacks=[\n",
    "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=15, restore_best_weights=True, min_delta=1e-4),\n",
    "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
    "    ]\n",
    ").history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Loss & Validation Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(history['val_loss'])\n",
    "plt.figure(figsize=(17, 4))\n",
    "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.title('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_predictions = np.array([])\n",
    "X_temp = X_test\n",
    "for reg in range(0, TEL, ATL):\n",
    "    pred_temp = model.predict(X_temp, verbose=0)\n",
    "    if (len(reg_predictions) == 0):\n",
    "        reg_predictions = pred_temp\n",
    "    else:\n",
    "        reg_predictions = np.concatenate((reg_predictions, pred_temp), axis=1)\n",
    "    X_temp = np.concatenate((X_temp[:, ATL:, :], pred_temp), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the predictions\n",
    "print(f\"Predictions shape: {reg_predictions.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"Prediction at 18:\")\n",
    "mean_squared_error = tfk.metrics.mean_squared_error(y_test.flatten(), reg_predictions.flatten()).numpy()\n",
    "print(f\"Mean Squared Error: {mean_squared_error}\")\n",
    "mean_absolute_error = tfk.metrics.mean_absolute_error(y_test.flatten(), reg_predictions.flatten()).numpy()\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error}\")\n",
    "print()\n",
    "\n",
    "print(\"Prediction at 9:\")\n",
    "y_test_9 = y_test[:, :9]\n",
    "reg_predictions_9 = reg_predictions[:, :9]\n",
    "mean_squared_error = tfk.metrics.mean_squared_error(y_test_9.flatten(), reg_predictions_9.flatten()).numpy()\n",
    "print(f\"Mean Squared Error: {mean_squared_error}\")\n",
    "mean_absolute_error = tfk.metrics.mean_absolute_error(y_test_9.flatten(), reg_predictions_9.flatten()).numpy()\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_MODEL = \"BidirectionalGRU\"\n",
    "if use_tpu:\n",
    "  # save model locally from tpu using Tensorflow's \"SavedModel\" format\n",
    "  save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "  model.save(NAME_MODEL, options=save_locally)\n",
    "else:\n",
    "  model.save(NAME_MODEL)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
